Week-4
Live data import - for real time updates
  Learned about importing live data in powerBI using get data option
  Allows data to be fetched directly from the web using urls
  The Dashboard updates Automatically as the source changes.
There aer four dominant ways to do it-each with a different power-latency tradeoff.
1.DirectQuery(True Live):Power BI doesn't store data, It queries the source in Real Time.
Sources:SQL Server
Latency: Seconds
Best for:Operational Dashboards
2.Streaming Datasets(Real-Time Events):Push data continuously via API.
Source:IoT, Logs,apps,sensors
Latency:Near real-Time(milliseconds-seconds)
Tools:REST API,AzureStream Analysis,Power Automate
3.Schedule Refresh(Near-Live):Based on timer Data Refreshs
Source:Excl,CSV,APIs,on-prem DBs
Latency: Every 15-30 mins(pro),more with Premium
Best for:Bussiness Reporting
4.Hybrid Tables(Best for both Worlds):
Recent data = Live
Historical data = imported
Requires Power BI Premium
Use case: Large datasets + fast visuals

Challenges:
  Not all websites allow data to import into powerBI
  Authentication issues 
  Login requirements
Data privacy and security restrictions

PowerBI:Get data->web-.paste url,choose basic 

Understanding APIs
  Acts as a communication bridge
  API keys are required to access live data

Difference between Error and null Value:
They look similar, but they signal very different failures.
#NullValue: Data is missing unknown,or not applicable.
No value exists.
Expected in real-world data
Can be intentional
#Error: Something went wrong during data capture,processing,or calculation.
Data exists but is invalid
Indicates failure or inconsistency
Must be fixed or Removed

#Zendesk:
  It is a customer support and ticket management system
  Used by company to collect and Apply Real world data or live Datasets
  We can't download data every time, that is the reason to connect the live data to power query.
  CRM - Custmer Relationship Management System

Concept of Outlayer:
An outlayer is not a mistake to delete. It's a question the data is asking you.
Finding an outlayer matters because it reveals truth at the edges-where system break.
Ignore them and you optimize for the past,Understand them and you Design for what's coming next.

In Data Visualization Data has 3 Types
These 3 are Important Based on Table Data calculatons.
1)Categorical Data:
It uses Bar chart when comparing data,Pie chart uses proportions in categorical Data.
Whenever you Visualizing categorical Data There must be no more than 5 to 6categories.
It is too complex Sum of all proportions = 100
2)Numerical Data: The data contains Numerical Values in the Table.
3)Time Waste Data:
In this Time series is calculated by line graph.
Time attribute:monthly/Yearly sales,you can create line graph and connect it to the bar graph,
because bar graph is optimal.

Views are three types in Data Visualization.
Table View, Model View, Report View
We can't Connect one Table to another Table until a same commen column have.
Data Modeling: It is also known as Schematic modeling.
It is Structuring your Data  using tools like PowerBI.
It is used in Multiple Table working Time.
The Main Table contains only UserId's only it is also known as fact Table.
The other small tables contains Indetail Information known as Dimension Tables.
Whenever we want to make a connection(Figjam) between two tables must present same column.
Relationships have 4 types:
Many to One (* + 1) Many columns in Table-A connect to one Matched column in Table-B. 
One to Many (1 + *) One column in Table-B connects to Many columns Which Matches in Table-A.
Many to Many (* + *) Many columns in Table-A connects to Many columns Which Matches in Table-B.
One to One (1 + 1) One column in Table-A connects to One matched column in Table-B.
Star schema : It is make connection between Fact table and Dimension Table.

KPI'S - Keep Performance Indicator:
It is used for better Visualization.
it is in Numerical form.
Kpi's are critical numbers used to track progress towards a goal.
Cards:it gives quick glimnce of Numerical Value
Database KEY's:
Primary Key:It is a main key unique and doesn't contain duplicates.
Foreign key:It have many duplicates.

ETL pipeline(Extract,Transform,Load):
  Helps to automate data process
  Ensures clean and consistent data

Task:create a github reposistory  and Update it Properly.
